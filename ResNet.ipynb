{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-vIFbYjUPe-"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch import nn\n",
        "import torchvision\n",
        "\n",
        "import json\n",
        "import math\n",
        "import torch\n",
        "import torchvision\n",
        "import random\n",
        "from torch.utils import data\n",
        "\n",
        "\n",
        "__all__ = ['VOCDataset', 'VOCRawTestDataset', 'load_data_voc']\n",
        "\n",
        "\n",
        "categories = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "\n",
        "\n",
        "# Dataset adapt for Yolo format (divided into cells)\n",
        "class VOCDataset(data.Dataset):\n",
        "\tdef __init__(self, dataset, train=True):\n",
        "\t\tself.dataset = dataset\n",
        "\t\tself.train = train\n",
        "\t\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.dataset)\n",
        "\t\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\timg, target = self.dataset[idx]\n",
        "\t\t\n",
        "\t\tif not isinstance(target['annotation']['object'], list):\n",
        "\t\t\ttarget['annotation']['object'] = [target['annotation']['object']]\n",
        "\t\tcount = len(target['annotation']['object'])\n",
        "\n",
        "\t\theight, width = int(target['annotation']['size']['height']), int(target['annotation']['size']['width'])\n",
        "\n",
        "\t\t# Image Augmentation\n",
        "\t\tif self.train:\n",
        "\t\t\t# randomly scaling and translation up to 20%\n",
        "\t\t\tif random.random() < 0.5:\n",
        "\t\t\t\t# use random value to decide scaling factor on x and y axis\n",
        "\t\t\t\trandom_height = random.random() * 0.2\n",
        "\t\t\t\trandom_width = random.random() * 0.2\n",
        "\t\t\t\t# use random value again to decide scaling factor for 4 borders\n",
        "\t\t\t\trandom_top = random.random() * random_height\n",
        "\t\t\t\trandom_left = random.random() * random_width\n",
        "\t\t\t\t# calculate new width and height and position\n",
        "\t\t\t\ttop = random_top * height\n",
        "\t\t\t\tleft = random_left * width\n",
        "\t\t\t\theight = height - random_height * height\n",
        "\t\t\t\twidth = width - random_width * width\n",
        "\t\t\t\t# crop image\n",
        "\t\t\t\timg = torchvision.transforms.functional.crop(img, int(top), int(left), int(height), int(width))\n",
        "\t\t\t\n",
        "\t\t\t\t# update target\n",
        "\t\t\t\tfor i in range(count):\n",
        "\t\t\t\t\tobj = target['annotation']['object'][i]\n",
        "\t\t\t\t\tobj['bndbox']['xmin'] = max(0, float(obj['bndbox']['xmin']) - left)\n",
        "\t\t\t\t\tobj['bndbox']['ymin'] = max(0, float(obj['bndbox']['ymin']) - top)\n",
        "\t\t\t\t\tobj['bndbox']['xmax'] = min(width, float(obj['bndbox']['xmax']) - left)\n",
        "\t\t\t\t\tobj['bndbox']['ymax'] = min(height, float(obj['bndbox']['ymax']) - top)\n",
        "\t\t\t\n",
        "\t\t\t# adjust saturation randomly up to 150%\n",
        "\t\t\tif random.random() < 0.5:\n",
        "\t\t\t\trandom_saturation = random.random() + 0.5\n",
        "\t\t\t\timg = torchvision.transforms.functional.adjust_saturation(img, random_saturation)\n",
        "\t\t\n",
        "\t\t# resize to 448*448\n",
        "\t\timg = torchvision.transforms.functional.resize(img, (448, 448))\n",
        "\n",
        "\t\t# update labels from absolute to relative\n",
        "\t\theight, width = float(height), float(width)\n",
        "\n",
        "\t\tfor i in range(count):\n",
        "\t\t\tobj = target['annotation']['object'][i]\n",
        "\t\t\tobj['bndbox']['xmin'] = float(obj['bndbox']['xmin']) / width\n",
        "\t\t\tobj['bndbox']['ymin'] = float(obj['bndbox']['ymin']) / height\n",
        "\t\t\tobj['bndbox']['xmax'] = float(obj['bndbox']['xmax']) / width\n",
        "\t\t\tobj['bndbox']['ymax'] = float(obj['bndbox']['ymax']) / height\n",
        "\n",
        "\t\t# Label Encoding\n",
        "\t\t# [{'name': '', 'xmin': '', 'ymin': '', 'xmax': '', 'ymax': '', }, {}, {}, ...]\n",
        "\t\t# ==>\n",
        "\t\t# [x, y  (relative to cell), width, height, 1 if exist (confidence),\n",
        "\t\t#  x, y  (relative to cell), width, height, 1 if exist (confidence),\n",
        "\t\t#  one-hot encoding of 20 categories]\n",
        "\t\tlabel = torch.zeros((7, 7, 30))\n",
        "\t\tfor i in range(count):\n",
        "\t\t\tobj = target['annotation']['object'][i]\n",
        "\t\t\txmin = obj['bndbox']['xmin']\n",
        "\t\t\tymin = obj['bndbox']['ymin']\n",
        "\t\t\txmax = obj['bndbox']['xmax']\n",
        "\t\t\tymax = obj['bndbox']['ymax']\n",
        "\t\t\tname = obj['name']\n",
        "\n",
        "\t\t\tif xmin == xmax or ymin == ymax:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tif xmin >= 1 or ymin >= 1 or xmax <= 0 or ymax <= 0:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t\n",
        "\t\t\tx = (xmin + xmax) / 2.0\n",
        "\t\t\ty = (ymin + ymax) / 2.0\n",
        "\n",
        "\t\t\twidth = xmax - xmin\n",
        "\t\t\theight = ymax - ymin\n",
        "\n",
        "\t\t\txidx = math.floor(x * 7.0)\n",
        "\t\t\tyidx = math.floor(y * 7.0)\n",
        "\t\t\t\n",
        "\n",
        "\t\t\t# According to the paper\n",
        "\t\t\t# if multiple objects exist in the same cell\n",
        "\t\t\t# pick the one with the largest area\n",
        "\t\t\tif label[yidx][xidx][4] == 1: # already have object\n",
        "\t\t\t\tif label[yidx][xidx][2] * label[yidx][xidx][3] < width * height:\n",
        "\t\t\t\t\tuse_data = True\n",
        "\t\t\t\telse: use_data = False\n",
        "\t\t\telse: use_data = True\n",
        "\n",
        "\t\t\tif use_data:\n",
        "\t\t\t\tfor offset in [0, 5]:\n",
        "\t\t\t\t\t# Transforming image relative coordinates to cell relative coordinates:\n",
        "\t\t\t\t\t# x - idx / 7.0 = x_cell / cell_count (7.0)\n",
        "\t\t\t\t\t# => x_cell = x * cell_count - idx = x * 7.0 - idx\n",
        "\t\t\t\t\t# y is the same\n",
        "\t\t\t\t\tlabel[yidx][xidx][0 + offset] = x * 7.0 - xidx\n",
        "\t\t\t\t\tlabel[yidx][xidx][1 + offset] = y * 7.0 - yidx\n",
        "\t\t\t\t\tlabel[yidx][xidx][2 + offset] = width\n",
        "\t\t\t\t\tlabel[yidx][xidx][3 + offset] = height\n",
        "\t\t\t\t\tlabel[yidx][xidx][4 + offset] = 1\n",
        "\t\t\t\tlabel[yidx][xidx][10 + categories.index(name)] = 1\n",
        "\n",
        "\t\treturn img, label\n",
        "\n",
        "\n",
        "# Raw Dataset for testing mAP, Precision and Recall\n",
        "# Target are \n",
        "class VOCRawTestDataset(data.Dataset):\n",
        "\tdef __init__(self, dataset):\n",
        "\t\tself.dataset = dataset\n",
        "\t\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.dataset)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\timg, target = self.dataset[idx]\n",
        "\n",
        "\t\tif not isinstance(target['annotation']['object'], list):\n",
        "\t\t\ttarget['annotation']['object'] = [target['annotation']['object']]\n",
        "\t\tcount = len(target['annotation']['object'])\n",
        "\n",
        "\t\theight, width = int(target['annotation']['size']['height']), int(target['annotation']['size']['width'])\n",
        "\n",
        "\t\t# resize to 448*448\n",
        "\t\timg = torchvision.transforms.functional.resize(img, (448, 448))\n",
        "\n",
        "\t\t# update labels from absolute to relative\n",
        "\t\theight, width = float(height), float(width)\n",
        "\n",
        "\t\tret_targets = []\n",
        "\n",
        "\t\tfor i in range(count):\n",
        "\t\t\tobj = target['annotation']['object'][i]\n",
        "\n",
        "\t\t\tret_targets.append({\n",
        "\t\t\t\t'xmin': float(obj['bndbox']['xmin']) / width,\n",
        "\t\t\t\t'ymin': float(obj['bndbox']['ymin']) / height,\n",
        "\t\t\t\t'xmax': float(obj['bndbox']['xmax']) / width,\n",
        "\t\t\t\t'ymax': float(obj['bndbox']['ymax']) / height,\n",
        "\t\t\t\t'category': categories.index(obj['name']),\n",
        "\t\t\t\t'difficult': obj['difficult'] == '1',\n",
        "\t\t\t})\n",
        "\t\t\n",
        "\t\treturn img, json.dumps(ret_targets)\n",
        "\n",
        "\n",
        "def load_data_voc(batch_size, num_workers=0, persistent_workers=False, download=True, test_shuffle=True):\n",
        "\t\"\"\"\n",
        "\tLoads the Pascal VOC dataset.\n",
        "\t:return: train_iter, test_iter, test_raw_iter\n",
        "\t\"\"\"\n",
        "\t# Load the dataset\n",
        "\ttrans = [\n",
        "\t\ttorchvision.transforms.ToTensor(),\n",
        "\t]\n",
        "\ttrans = torchvision.transforms.Compose(trans)\n",
        "\tvoc2007_trainval = torchvision.datasets.VOCDetection(root='../data/VOCDetection/', year='2007', image_set='trainval', download=download, transform=trans)\n",
        "\tvoc2007_test = torchvision.datasets.VOCDetection(root='../data/VOCDetection/', year='2007', image_set='test', download=download, transform=trans)\n",
        "\tvoc2012_train = torchvision.datasets.VOCDetection(root='../data/VOCDetection/', year='2012', image_set='train', download=download, transform=trans)\n",
        "\tvoc2012_val = torchvision.datasets.VOCDetection(root='../data/VOCDetection/', year='2012', image_set='val', download=download, transform=trans)\n",
        "\treturn (\n",
        "\t\tdata.DataLoader(VOCDataset(data.ConcatDataset([voc2007_trainval, voc2007_test, voc2012_train]), train=True), \n",
        "\t\t\tbatch_size, shuffle=True, num_workers=num_workers, persistent_workers=persistent_workers), \n",
        "\t\tdata.DataLoader(VOCDataset(voc2012_val, train=False), \n",
        "\t\t\tbatch_size, shuffle=test_shuffle, num_workers=num_workers, persistent_workers=persistent_workers),\n",
        "\t\tdata.DataLoader(VOCRawTestDataset(voc2012_val), \n",
        "\t\t\tbatch_size, shuffle=test_shuffle, num_workers=num_workers, persistent_workers=persistent_workers)\n",
        "\t)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276,
          "referenced_widgets": [
            "7fa97b5ae8454361a5f2c9f2ec3060dd",
            "94764f5b7ea241b5bf6d10ad42f8b0e5",
            "beb9084e8f394f9bb8147f76af1cc929",
            "63e579fc4b8548feaed3b441fd1cf2a6",
            "e00657afc0ba4ba3a78fa7ad329d9018",
            "0ee224f9f9b84f65bdb89b4db645bb6d",
            "68859a2729064fddaf603b85028f3954",
            "fd1db780edfd4e26942d5e56af4cd16a",
            "e444f4064b2c44a19ccefd6bf1eb87d4",
            "cdd94c09c4864ea48a84b8e9b8e84ec5",
            "48247bf0644647dab8aad2ec5e07bca4",
            "13f70f911e234fbabb88163c48a0d8ed",
            "0780a1586db74b24bf0a538e5bf7f7dd",
            "c20ad8749f3040b4afee3ef9bbd02731",
            "495c067312564939be4047d682f68f75",
            "6a60adfd7a1343c5b1e414f3c52d2d2d",
            "772717d673bd429c878aa81f1ef86295",
            "d120bc4bcc2047c8ab03b222875dc3ef",
            "d7143f2b364145648157c3210a7485f0",
            "7be6a8d22ba948cba48b87e9cded5eac",
            "42b17391227b457aae0158dbb30996d3",
            "1c454ed3c7664257a3b435301afc237d",
            "c1158e7fb99e436aa7beaa70d85c5b46",
            "f4e154849346411b8e98926fdaf49952",
            "66aae6d7af344e23bf1de595a96dee11",
            "79877b0fefa344629f64f28d6791a34e",
            "e412216e7c2743b9bcf75f0d88016898",
            "d63469d63d9944188045218f1da4b46e",
            "dbf6853fc87845c981f01b294cbc65e9",
            "e15d51ed815947eca43d3b53cd922638",
            "70dd342df73344c699d1495d85c8d27a",
            "971fd61c1ff84a71893fa89bea2a269e",
            "d92092b0fef74fe7b015b2789c8f6a8d"
          ]
        },
        "id": "LlpL-YENUPe_",
        "outputId": "48420472-89b2-4dcd-d286-058d6a9e7c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar to ../data/VOCDetection/VOCtrainval_06-Nov-2007.tar\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/460032000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fa97b5ae8454361a5f2c9f2ec3060dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/VOCDetection/VOCtrainval_06-Nov-2007.tar to ../data/VOCDetection/\n",
            "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar to ../data/VOCDetection/VOCtest_06-Nov-2007.tar\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/451020800 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13f70f911e234fbabb88163c48a0d8ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/VOCDetection/VOCtest_06-Nov-2007.tar to ../data/VOCDetection/\n",
            "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar to ../data/VOCDetection/VOCtrainval_11-May-2012.tar\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1999639040 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1158e7fb99e436aa7beaa70d85c5b46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/VOCDetection/VOCtrainval_11-May-2012.tar to ../data/VOCDetection/\n",
            "Using downloaded and verified file: ../data/VOCDetection/VOCtrainval_11-May-2012.tar\n",
            "Extracting ../data/VOCDetection/VOCtrainval_11-May-2012.tar to ../data/VOCDetection/\n"
          ]
        }
      ],
      "source": [
        "train_iter, test_iter, test_iter_raw = load_data_voc(batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "__all__ = ['Accumulator', 'Timer']\n",
        "\n",
        "\n",
        "# from d2l\n",
        "class Accumulator(object):\n",
        "    \"\"\"\n",
        "    Sum a list of numbers over time\n",
        "    from: https://github.com/dsgiitr/d2l-pytorch/blob/master/d2l/base.py\n",
        "    \"\"\"\n",
        "    def __init__(self, n):\n",
        "        self.data = [0.0] * n\n",
        "    def add(self, *args):\n",
        "        self.data = [a + b for a, b in zip(self.data, args)]\n",
        "    def reset(self):\n",
        "        self.data = [0] * len(self.data)\n",
        "    def __getitem__(self, i):\n",
        "        return self.data[i]\n",
        "\n",
        "\n",
        "class Timer(object):\n",
        "    \"\"\"Record multiple running times.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.times = []\n",
        "        self.start()\n",
        "        \n",
        "    def start(self):\n",
        "        \"\"\"Start the timer\"\"\"\n",
        "        self.start_time = time.time()\n",
        "    \n",
        "    def stop(self):\n",
        "        \"\"\"Stop the timer and record the time in a list\"\"\"\n",
        "        self.times.append(time.time() - self.start_time)\n",
        "        return self.times[-1]\n",
        "        \n",
        "    def avg(self):\n",
        "        \"\"\"Return the average time\"\"\"\n",
        "        return sum(self.times)/len(self.times)\n",
        "    \n",
        "    def sum(self):\n",
        "        \"\"\"Return the sum of time\"\"\"\n",
        "        return sum(self.times)\n",
        "        \n",
        "    def cumsum(self):\n",
        "        \"\"\"Return the accumuated times\"\"\"\n",
        "        return np.array(self.times).cumsum().tolist()"
      ],
      "metadata": {
        "id": "-SdckLTcgi4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import cmp_to_key\n",
        "import json\n",
        "from enum import Enum\n",
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "__all__ = ['InterpolationMethod', 'CalculationMetrics', 'ObjectDetectionMetricsCalculator']\n",
        "\n",
        "\n",
        "class InterpolationMethod(Enum):\n",
        "\tInterpolation_11 = 1\n",
        "\tInterpolation_101 = 2\n",
        "\n",
        "\n",
        "class CalculationMetrics():\n",
        "\tdef __init__(self, IoU: float, confidence: float, mustbe_FP: bool, is_difficult: bool):\n",
        "\t\t\"\"\"Initialization for `CalculationMetrics`\n",
        "\n",
        "\t\tArgs:\n",
        "\t\t\tIoU (float): intersection over union with ground truth\n",
        "\t\t\tconfidence (float): detection confidence\n",
        "\t\t\tmustbe_FP (bool): if there is already another detection having higher IoU with the same ground truth, then this detection must be False Positive\n",
        "\t\t\tis_difficult (bool): if the ground truth is difficult, then this detection may be neglected in certain cases\n",
        "\t\t\"\"\"\n",
        "\t\tself.IoU = IoU\n",
        "\t\tself.confidence = confidence\n",
        "\t\tself.mustbe_FP = mustbe_FP\n",
        "\t\tself.is_difficult = is_difficult\n",
        "\n",
        "\n",
        "def compare_metrics(metrics1: CalculationMetrics, metrics2: CalculationMetrics):\n",
        "\tif metrics1.confidence == metrics2.confidence:\n",
        "\t\treturn metrics2.IoU - metrics1.IoU\n",
        "\treturn metrics2.confidence - metrics1.confidence\n",
        "\n",
        "\n",
        "class ObjectDetectionMetricsCalculator():\n",
        "\t# data\n",
        "\t# [       # classes\n",
        "\t#   {\n",
        "\t#      \"data\": [     # data\n",
        "\t#         <CalculationMetrics>\n",
        "\t#      ],\n",
        "\t#      \"detection\": <int>,\n",
        "\t#      \"truth\": <int>\n",
        "\t#   }\n",
        "\t# ]\n",
        "\n",
        "\tdef __init__(self, num_classes: int, confidence_thres: float):\n",
        "\t\t\"\"\"ObjectDetectionMetricsCalculator Initialization\n",
        "\n",
        "\t\tArgs:\n",
        "\t\t\tnum_classes (int): number of classes detector can classify\n",
        "\t\t\tconfidence_thres (float): confidence threshold. if the detection's confidence is smaller than the threshold, it would not be counted as a detection. In other words, it would be neither TP nor FP.\n",
        "\t\t\"\"\"\n",
        "\t\t# initialize data\n",
        "\t\tself.data = [{\"data\": [], \"detection\": 0, \"truth\": 0} for _ in range(num_classes)]\n",
        "\t\tself.confidence_thres = confidence_thres\n",
        "\n",
        "\n",
        "\tdef add_image_data(self, pred: torch.Tensor, truth: str):\n",
        "\t\t\"\"\"Add new image data for calculating metrics\n",
        "\n",
        "\t\tArgs:\n",
        "\t\t\tpred (torch.Tensor): detection prediction\n",
        "\t\t\ttruth (str): ground truth json string\n",
        "\t\t\"\"\"\n",
        "\t\tpred = pred.reshape(-1, 30)\n",
        "\t\ttruth = json.loads(truth)\n",
        "\n",
        "\t\tchoose_truth_index = [None for _ in range(pred.shape[0])]\n",
        "\t\tiou = [0 for _ in range(pred.shape[0])]\n",
        "\n",
        "\t\tfor i in range(pred.shape[0]):\n",
        "\t\t\tscore, cat = pred[i][10:30].max(dim=0)\n",
        "\t\t\tconfidence = pred[i][4]\n",
        "\t\t\t# filter by confidence threshold\n",
        "\t\t\tif confidence * score < self.confidence_thres: continue\n",
        "\t\t\t\n",
        "\t\t\tx, y, w, h = pred[i][0:4]\n",
        "\t\t\t# calculate cell index\n",
        "\t\t\txidx = i % 7\n",
        "\t\t\tyidx = i // 7\n",
        "\t\t\t# transform cell relative coordinates to image relative coordinates\n",
        "\t\t\txhat = (x + xidx) / 7.0\n",
        "\t\t\tyhat = (y + yidx) / 7.0\n",
        "\n",
        "\t\t\txmin_hat = xhat - w / 2\n",
        "\t\t\txmax_hat = xhat + w / 2\n",
        "\t\t\tymin_hat = yhat - h / 2\n",
        "\t\t\tymax_hat = yhat + h / 2\n",
        "\n",
        "\t\t\tfor j in range(len(truth)):\n",
        "\t\t\t\tbbox = truth[j]\n",
        "\t\t\t\t# judge whether is same class\n",
        "\t\t\t\tif cat != bbox['category']: continue\n",
        "\t\t\t\t# calculate IoU\n",
        "\t\t\t\txmin, ymin, xmax, ymax = bbox['xmin'], bbox['ymin'], bbox['xmax'], bbox['ymax']\n",
        "\t\t\t\twi = min(xmax, xmax_hat) - max(xmin, xmin_hat)\n",
        "\t\t\t\twi = max(wi, 0)\n",
        "\t\t\t\thi = min(ymax, ymax_hat) - max(ymin, ymin_hat)\n",
        "\t\t\t\thi = max(hi, 0)\n",
        "\t\t\t\tintersection = wi * hi\n",
        "\t\t\t\tunion = (xmax - xmin) * (ymax - ymin) + (xmax_hat - xmin_hat) * (ymax_hat - ymin_hat) - intersection\n",
        "\t\t\t\tthis_iou = intersection / (union + 1e-6)\n",
        "\t\t\t\t# determine whether to choose this ground truth\n",
        "\t\t\t\tif iou[i] is None: choose = True\n",
        "\t\t\t\telif iou[i] < this_iou: choose = True\n",
        "\t\t\t\telse: choose = False\n",
        "\t\t\t\t# if choose, assign value\n",
        "\t\t\t\tif choose:\n",
        "\t\t\t\t\tiou[i] = this_iou\n",
        "\t\t\t\t\tchoose_truth_index[i] = j\n",
        "\t\t# init a bool array for judging mustbe_FP later\n",
        "\t\ttruth_chosen = [False for _ in range(len(truth))]\n",
        "\t\t# sort according to IoU\n",
        "\t\tsort_idx = np.argsort(iou)[::-1]\n",
        "\t\t# add into metrics\n",
        "\t\tfor i in sort_idx:\n",
        "\t\t\tscore, cat = pred[i][10:30].max(dim=0)\n",
        "\t\t\tconfidence = pred[i][4]\n",
        "\t\t\t# filter by confidence threshold\n",
        "\t\t\tif confidence * score < self.confidence_thres: continue\n",
        "\n",
        "\t\t\ttruth_index = choose_truth_index[i]\n",
        "\t\t\tif truth_index == None: \n",
        "\t\t\t\tmustbe_FP = True\n",
        "\t\t\t\tis_difficult = False\n",
        "\t\t\telif truth_chosen[truth_index]:\n",
        "\t\t\t\tmustbe_FP = True\n",
        "\t\t\t\tis_difficult = truth[choose_truth_index[i]]['difficult']\n",
        "\t\t\telse: \n",
        "\t\t\t\tmustbe_FP = False\n",
        "\t\t\t\ttruth_chosen[choose_truth_index[i]] = True\n",
        "\t\t\t\tis_difficult = truth[choose_truth_index[i]]['difficult']\n",
        "\n",
        "\t\t\tself.data[cat]['data'].append(CalculationMetrics(iou[i], float(confidence * score), mustbe_FP, is_difficult))\n",
        "\n",
        "\t\t\t# update detection statistics\n",
        "\t\t\tself.data[cat]['detection'] += 1\n",
        "\t\t# update ground truth statistics\n",
        "\t\tfor bbox in truth:\n",
        "\t\t\tif bbox['difficult']: continue\n",
        "\t\t\tself.data[bbox['category']]['truth'] += 1\n",
        "\n",
        "\n",
        "\tdef calculate_precision_recall(self, iou_thres: float, class_idx: int) -> list:\n",
        "\t\t\"\"\"Calculate Precision-Recall Data according to IoU threshold\n",
        "\n",
        "\t\tArgs:\n",
        "\t\t\tiou_thres (float): IoU threshold\n",
        "\t\t\tclass_idx (int): Class Index\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tlist: `[{\"precision\": <precision>, \"recall\": <recall>}]`\n",
        "\t\t\"\"\"\n",
        "\t\tret = []\n",
        "\t\t# retrieve count\n",
        "\t\ttruth_cnt = self.data[class_idx]['truth']\n",
        "\t\t# accumulated TP\n",
        "\t\tacc_TP = 0\n",
        "\t\t# accumulated difficult count\n",
        "\t\tacc_difficult = 0\n",
        "\t\t# sort metrics by confidence\n",
        "\t\tdata = sorted(self.data[class_idx]['data'], key=cmp_to_key(compare_metrics))\n",
        "\t\tfor i, metrics in enumerate(data):\n",
        "\t\t\tif metrics.IoU >= iou_thres and not metrics.mustbe_FP and not metrics.is_difficult:\n",
        "\t\t\t\tacc_TP += 1\n",
        "\t\t\tif metrics.is_difficult:\n",
        "\t\t\t\tacc_difficult += 1\n",
        "\t\t\tif i + 1 - acc_difficult > 0:\n",
        "\t\t\t\tret.append({\n",
        "\t\t\t\t\t'precision': acc_TP / (i + 1 - acc_difficult),\n",
        "\t\t\t\t\t'recall': acc_TP / truth_cnt\n",
        "\t\t\t\t})\n",
        "\t\t\n",
        "\t\treturn ret\n",
        "\n",
        "\n",
        "\tdef calculate_average_precision(self, iou_thres: float, class_idx: int, itpl_option: InterpolationMethod) -> float:\n",
        "\t\t\"\"\"Calculate Average Precision (AP)\n",
        "\n",
        "\t\tArgs:\n",
        "\t\t\tiou_thres (float): IoU Threshold\n",
        "\t\t\tclass_idx (int): Class Index\n",
        "\t\t\titpl_option (InterpolationMethod): Interpolation Method\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tfloat: AP of specified class using provided interpolation method\n",
        "\t\t\"\"\"\n",
        "\t\tprl = self.calculate_precision_recall(iou_thres=iou_thres, class_idx=class_idx)\n",
        "\n",
        "\t\tif itpl_option == InterpolationMethod.Interpolation_11:\n",
        "\t\t\tintp_pts = [0.1 * i for i in range(11)]\n",
        "\t\telif itpl_option == InterpolationMethod.Interpolation_101:\n",
        "\t\t\tintp_pts = [0.01 * i for i in range(101)]\n",
        "\t\telse:\n",
        "\t\t\traise Exception('Unknown Interpolation Method')\n",
        "\n",
        "\t\tmax_dict = {}\n",
        "\t\tgmax = 0\n",
        "\n",
        "\t\tfor pr in prl[::-1]:\n",
        "\t\t\tgmax = max(gmax, pr['precision'])\n",
        "\t\t\tmax_dict[pr['recall']] = gmax\n",
        "\n",
        "\t\tif len(max_dict) < 1: return 0.\n",
        "\n",
        "\t\tmax_keys = max_dict.keys()\n",
        "\t\tmax_keys = sorted(max_keys)\n",
        "\n",
        "\t\tkey_ptr = len(max_keys) - 2\n",
        "\t\tlast_key = max_keys[-1]\n",
        "\n",
        "\t\tAP = 0\n",
        "\n",
        "\t\tfor query in intp_pts[::-1]:\n",
        "\t\t\tif key_ptr < 0:\n",
        "\t\t\t\tif query > last_key:\n",
        "\t\t\t\t\tans = 0\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tans = max_dict[last_key]\n",
        "\t\t\telse:\n",
        "\t\t\t\tif query > last_key:\n",
        "\t\t\t\t\tans = 0\n",
        "\t\t\t\telif query > max_keys[key_ptr]:\n",
        "\t\t\t\t\tans = max_dict[last_key]\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\twhile key_ptr >= 0:\n",
        "\t\t\t\t\t\tif query > max_keys[key_ptr]:\n",
        "\t\t\t\t\t\t\tbreak\n",
        "\t\t\t\t\t\tlast_key = max_keys[key_ptr]\n",
        "\t\t\t\t\t\tkey_ptr -= 1\n",
        "\t\t\t\t\tans = max_dict[last_key]\n",
        "\t\t\tAP += ans\n",
        "\n",
        "\t\tAP /= len(intp_pts)\n",
        "\t\treturn AP\n",
        "\n",
        "\n",
        "\tdef calculate_mAP(self, iou_thres: float, itpl_option: InterpolationMethod) -> float:\n",
        "\t\t\"\"\"calculate mAP using given IoU threshold and interpolation method\n",
        "\n",
        "\t\tArgs:\n",
        "\t\t\tiou_thres (float): IoU threshold\n",
        "\t\t\titpl_option (InterpolationMethod): Interpolation Method\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tfloat: Mean Average Precision (mAP)\n",
        "\t\t\"\"\"\n",
        "\t\tmAP = 0\n",
        "\t\tfor c in range(len(self.data)):\n",
        "\t\t\tmAP += self.calculate_average_precision(iou_thres, c, itpl_option)\n",
        "\t\tmAP /= len(self.data)\n",
        "\n",
        "\t\treturn mAP\n",
        "\n",
        "\n",
        "\tdef calculate_VOCmAP(self) -> float:\n",
        "\t\t\"\"\"calculate VOCmAP: mAP with IoU thres = .5, interpolate by 0.1\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tfloat: VOC mAP\n",
        "\t\t\"\"\"\n",
        "\t\treturn self.calculate_mAP(0.5, InterpolationMethod.Interpolation_11)\n",
        "\n",
        "\n",
        "\tdef calculate_COCOmAP50(self) -> float:\n",
        "\t\t\"\"\"calculate COCO mAP @50 (AP@.5): expand VOCmAP50, interpolate by 0.01\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tfloat: AP@.5\n",
        "\t\t\"\"\"\n",
        "\t\treturn self.calculate_mAP(0.5, InterpolationMethod.Interpolation_101)\n",
        "\n",
        "\n",
        "\tdef calculate_COCOmAP75(self) -> float:\n",
        "\t\t\"\"\"calculate COCO mAP @75 (AP@.75): AP@.5, but with IoU thres = .75\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tfloat: AP@.75\n",
        "\t\t\"\"\"\n",
        "\t\treturn self.calculate_mAP(0.75, InterpolationMethod.Interpolation_101)\n",
        "\n",
        "\n",
        "\tdef calculate_COCOmAP(self) -> float:\n",
        "\t\t\"\"\"calculate COCO mAP: expand AP@.5 and AP@.75. IoU thres from .5 to .95\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\tfloat: COCO mAP\n",
        "\t\t\"\"\"\n",
        "\t\tious = [0.5 + 0.05 * i for i in range(10)]\n",
        "\t\tcoco_map = 0\n",
        "\t\tfor iou in ious:\n",
        "\t\t\tcoco_map += self.calculate_mAP(iou, InterpolationMethod.Interpolation_101)\n",
        "\t\tcoco_map /= len(ious)\n",
        "\t\treturn coco_map\n"
      ],
      "metadata": {
        "id": "4oieY4SEgoKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import Optional\n",
        "import torch\n",
        "import torchvision\n",
        "import random\n",
        "import cv2\n",
        "import numpy\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "\n",
        "__all__ = ['draw_box', 'draw_detection_result', 'draw_ground_truth', 'PIL_to_cv2', 'cv2_to_PIL', 'tensor_to_PIL', 'tensor_to_cv2', 'Animator', 'draw_precision_recall']\n",
        "\n",
        "\n",
        "categories = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
        "# 20 random color for labeling\n",
        "colors = [(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) for _ in range(20)]\n",
        "\n",
        "\n",
        "def draw_precision_recall(pr_data: list, class_idx: Optional[int]=None):\n",
        "\t\"\"\"Draw Precision-Recall Curve\n",
        "\n",
        "\tArgs:\n",
        "\t\tpr_data (list): Precision Recall Curve Data\n",
        "\t\tclass_idx (Optional[int]): Class index, used to render title\n",
        "\t\"\"\"\n",
        "\tp = [data['precision'] for data in pr_data]\n",
        "\tr = [data['recall'] for data in pr_data]\n",
        "\n",
        "\tplt.plot(r, p, 'o-', color='r')\n",
        "\tplt.xlabel(\"Recall\")\n",
        "\tplt.ylabel(\"Precision\")\n",
        "\n",
        "\tif class_idx is not None:\n",
        "\t\tplt.title(categories[class_idx])\n",
        "\n",
        "\tplt.show()\n",
        "\n",
        "\n",
        "def draw_box(img, x, y, w, h, score, category):\n",
        "\t\"\"\"\n",
        "\tTool function to draw confidence box on image\n",
        "\t:param img: numpy image to be rendered\n",
        "\t:param x, y: relative center of box\n",
        "\t:param w, h: relative size of box\n",
        "\t:param score: confidence score\n",
        "\t:param category: category of object\n",
        "\t:return: image with box\n",
        "\t\"\"\"\n",
        "\theight = img.shape[0] * h\n",
        "\twidth = img.shape[1] * w\n",
        "\tleft = img.shape[1] * x - width / 2\n",
        "\ttop = img.shape[0] * y - height / 2\n",
        "\n",
        "\tcolor = colors[category]\n",
        "\ttext = categories[category] + \" \" + str(float(score))\n",
        "\tcv2.rectangle(img, (int(left), int(top)), (int(left + width), int(top + height)), color, 2)\n",
        "\n",
        "\ttext_size, baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
        "\tp1 = (int(left), int(top) - text_size[1])\n",
        "\n",
        "\tcv2.rectangle(img,\n",
        "\t\t(p1[0] - 2//2, p1[1] - 2 - baseline),\n",
        "\t\t(p1[0] + text_size[0], p1[1] + text_size[1]), color, -1)\n",
        "\tcv2.putText(img, text,\n",
        "\t\t(p1[0], p1[1] + baseline),\n",
        "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1, 8)\n",
        "\t\n",
        "\treturn img\n",
        "\n",
        "\n",
        "def draw_detection_result(img, pred, raw=False, thres=0.1):\n",
        "\t\"\"\"\n",
        "\tTool function to draw detection result on image\n",
        "\t:param img: numpy image to be rendered\n",
        "\t:param pred: detection result (torch.Tensor)\n",
        "\t:param raw: if true, two dimension of detection results will be rendered (5 * 2 + 20)\n",
        "\t:param thres: threshold to filter out low confidence boxes\n",
        "\t:return: image with detection result\n",
        "\t\"\"\"\n",
        "\tif raw:\n",
        "\t\toffsets = [0, 5]\n",
        "\telse: offsets = [0]\n",
        "\n",
        "\tfor offset in offsets:\n",
        "\t\tpred = pred.reshape((-1, 30))\n",
        "\t\tfor i in range(pred.shape[0]):\n",
        "\t\t\tx, y, w, h, iou = pred[i][0 + offset : 5 + offset]\n",
        "\n",
        "\t\t\t# calculate cell index\n",
        "\t\t\txidx = i % 7\n",
        "\t\t\tyidx = i // 7\n",
        "\n",
        "\t\t\t# transform cell relative coordinates to image relative coordinates\n",
        "\t\t\tx = (x + xidx) / 7.0\n",
        "\t\t\ty = (y + yidx) / 7.0\n",
        "\n",
        "\t\t\tscore, cat = pred[i][10:30].max(dim=0)\n",
        "\t\t\tif iou * score < thres: continue\n",
        "\t\t\timg = draw_box(img, x, y, w, h, score * iou, cat)\n",
        "\n",
        "\treturn img\n",
        "\n",
        "\n",
        "def draw_ground_truth(img, truth):\n",
        "\t\"\"\"\n",
        "\tTool function to draw ground truth\n",
        "\t:param img: numpy image to be rendered\n",
        "\t:param pred: truth bbox in json format (str)\n",
        "\t:return: image with ground truth bbox\n",
        "\t\"\"\"\n",
        "\tpred = json.loads(truth)\n",
        "\tfor bbox in pred:\n",
        "\t\txmin, ymin, xmax, ymax = bbox['xmin'], bbox['ymin'], bbox['xmax'], bbox['ymax']\n",
        "\t\tw = xmax - xmin\n",
        "\t\th = ymax - ymin\n",
        "\t\tx = (xmin + xmax) / 2\n",
        "\t\ty = (ymin + ymax) / 2\n",
        "\t\timg = draw_box(img, x, y, w, h, 1, bbox['category'])\n",
        "\treturn img\n",
        "\n",
        "\n",
        "def tensor_to_PIL(img):\n",
        "\t\"\"\"Convert a tensor into a PIL image\"\"\"\n",
        "\tto_pil = torchvision.transforms.ToPILImage()\n",
        "\treturn to_pil(img.cpu()).convert('RGB')\n",
        "\n",
        "\n",
        "def tensor_to_cv2(img):\n",
        "\treturn PIL_to_cv2(tensor_to_PIL(img))\n",
        "\n",
        "\n",
        "def PIL_to_cv2(img):\n",
        "\t\"\"\"\n",
        "\tTool function to convert PIL image to cv2 image\n",
        "\t:param img: PIL image\n",
        "\t:return: cv2 image\n",
        "\t\"\"\"\n",
        "\timg = numpy.array(img)\n",
        "\timg = img[:, :, ::-1].copy()\n",
        "\treturn img\n",
        "\n",
        "\n",
        "def cv2_to_PIL(img):\n",
        "\t\"\"\"\n",
        "\tTool function to convert cv2 image to PIL image\n",
        "\t:param img: cv2 image\n",
        "\t:return: PIL image\n",
        "\t\"\"\"\n",
        "\timg = img[:, :, ::-1].copy()\n",
        "\timg = Image.fromarray(img)\n",
        "\treturn img\n",
        "\n",
        "\n",
        "# from d2l\n",
        "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
        "    \"\"\"A utility function to set matplotlib axes\"\"\"\n",
        "    axes.set_xlabel(xlabel)\n",
        "    axes.set_ylabel(ylabel)\n",
        "    axes.set_xscale(xscale)\n",
        "    axes.set_yscale(yscale)\n",
        "    axes.set_xlim(xlim)\n",
        "    axes.set_ylim(ylim)\n",
        "    if legend: axes.legend(legend)\n",
        "    axes.grid()\n",
        "\n",
        "\n",
        "# from d2l\n",
        "class Animator(object):\n",
        "    def __init__(self, xlabel=None, ylabel=None, legend=[], xlim=None,\n",
        "                 ylim=None, xscale='linear', yscale='linear', fmts=None,\n",
        "                 nrows=1, ncols=1, figsize=(3.5, 2.5)):\n",
        "        \"\"\"Incrementally plot multiple lines.\"\"\"\n",
        "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
        "        if nrows * ncols == 1: self.axes = [self.axes,]\n",
        "        # use a lambda to capture arguments\n",
        "        self.config_axes = lambda : set_axes(\n",
        "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
        "        self.X, self.Y, self.fmts = None, None, fmts\n",
        "\n",
        "    def add(self, x, y):\n",
        "        \"\"\"Add multiple data points into the figure.\"\"\"\n",
        "        if not hasattr(y, \"__len__\"): y = [y]\n",
        "        n = len(y)\n",
        "        if not hasattr(x, \"__len__\"): x = [x] * n\n",
        "        if not self.X: self.X = [[] for _ in range(n)]\n",
        "        if not self.Y: self.Y = [[] for _ in range(n)]\n",
        "        if not self.fmts: self.fmts = ['-'] * n\n",
        "        for i, (a, b) in enumerate(zip(x, y)):\n",
        "            if a is not None and b is not None:\n",
        "                self.X[i].append(a)\n",
        "                self.Y[i].append(b)\n",
        "        self.axes[0].cla()\n",
        "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
        "            self.axes[0].plot(x, y, fmt)\n",
        "        self.config_axes()\n",
        "        display.display(self.fig)\n",
        "        display.clear_output(wait=True)\n"
      ],
      "metadata": {
        "id": "l-tOWY8Fgrzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "__all__ = ['weight_init']\n",
        "\n",
        "\n",
        "# From https://gist.github.com/jeasinema/ed9236ce743c8efaf30fa2ff732749f5\n",
        "def weight_init(m):\n",
        "    '''\n",
        "    Usage:\n",
        "        model = Model()\n",
        "        model.apply(weight_init)\n",
        "    '''\n",
        "    if isinstance(m, nn.Conv1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.BatchNorm1d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm3d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.LSTM):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.LSTMCell):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.GRU):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.GRUCell):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n"
      ],
      "metadata": {
        "id": "HnGCnTGohNao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "from torch.nn import functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "lambda_coord = 5.\n",
        "lambda_noobj = .5\n",
        "\n",
        "\n",
        "__all__ = ['YoloBackbone', 'Yolo', 'YoloPretrain', 'yolo_loss', 'pretrain', 'train', 'nms']\n",
        "\n",
        "\n",
        "class YoloBackbone(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(YoloBackbone, self).__init__()\n",
        "\t\tconv1 = nn.Sequential(\n",
        "\t\t\t# [#, 448, 448, 3] => [#, 224, 224, 64]\n",
        "\t\t\tnn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
        "\t\t\tnn.BatchNorm2d(64),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True)\n",
        "\t\t)\n",
        "\t\t# [#, 224, 224, 64] => [#, 112, 112, 64]\n",
        "\t\tpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\t\tconv2 = nn.Sequential(\n",
        "\t\t\t# [#, 112, 112, 64] => [#, 112, 112, 192]\n",
        "\t\t\tnn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "\t\t\tnn.BatchNorm2d(192),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True)\n",
        "\t\t)\n",
        "\t\t# [#, 112, 112, 192] => [#, 56, 56, 192]\n",
        "\t\tpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\t\tconv3 = nn.Sequential(\n",
        "\t\t\t# [#, 56, 56, 192] => [#, 56, 56, 128]\n",
        "\t\t\tnn.Conv2d(192, 128, kernel_size=1),\n",
        "\t\t\tnn.BatchNorm2d(128),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True),\n",
        "\t\t\t# [#, 56, 56, 128] => [#, 56, 56, 256]\n",
        "\t\t\tnn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "\t\t\tnn.BatchNorm2d(256),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True),\n",
        "\t\t\t# [#, 56, 56, 256] => [#, 56, 56, 256]\n",
        "\t\t\tnn.Conv2d(256, 256, kernel_size=1),\n",
        "\t\t\tnn.BatchNorm2d(256),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True),\n",
        "\t\t\t# [#, 56, 56, 256] => [#, 56, 56, 512]\n",
        "\t\t\tnn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "\t\t\tnn.BatchNorm2d(512),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True)\n",
        "\t\t)\n",
        "\t\t# [#, 56, 56, 512] => [#, 28, 28, 512]\n",
        "\t\tpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\t\t\n",
        "\t\tconv4_part = nn.Sequential(\n",
        "\t\t\t# [#, 28, 28, 512] => [#, 28, 28, 256]\n",
        "\t\t\tnn.Conv2d(512, 256, kernel_size=1),\n",
        "\t\t\tnn.BatchNorm2d(256),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True),\n",
        "\t\t\t# [#, 28, 28, 256] => [#, 28, 28, 512]\n",
        "\t\t\tnn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "\t\t\tnn.BatchNorm2d(512),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True)\n",
        "\t\t)\n",
        "\t\tconv4_modules = []\n",
        "\t\tfor _ in range(4):\n",
        "\t\t\tconv4_modules.append(conv4_part)\n",
        "\t\tconv4 = nn.Sequential(\n",
        "\t\t\t*conv4_modules,\n",
        "\t\t\t# [#, 28, 28, 512] => [#, 28, 28, 512]\n",
        "\t\t\tnn.Conv2d(512, 512, kernel_size=1),\n",
        "\t\t\tnn.BatchNorm2d(512),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True),\n",
        "\t\t\t# [#, 28, 28, 512] => [#, 28, 28, 1024]\n",
        "\t\t\tnn.Conv2d(512, 1024, kernel_size=3, padding=1),\n",
        "\t\t\tnn.BatchNorm2d(1024),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True)\n",
        "\t\t)\n",
        "\t\t# [#, 28, 28, 1024] => [#, 14, 14, 1024]\n",
        "\t\tpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\t\t# [#, 14, 14, 1024] => [#, 14, 14, 1024]\n",
        "\t\tconv5 = nn.Sequential(\n",
        "\t\t\t# [#, 14, 14, 1024] => [#, 14, 14, 512]\n",
        "\t\t\tnn.Conv2d(1024, 512, kernel_size=1),\n",
        "\t\t\tnn.BatchNorm2d(512),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True),\n",
        "\t\t\t# [#, 14, 14, 512] => [#, 14, 14, 1024]\n",
        "\t\t\tnn.Conv2d(512, 1024, kernel_size=3, padding=1),\n",
        "\t\t\tnn.BatchNorm2d(1024),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True),\n",
        "\t\t\t# [#, 14, 14, 1024] => [#, 14, 14, 512]\n",
        "\t\t\tnn.Conv2d(1024, 512, kernel_size=1),\n",
        "\t\t\tnn.BatchNorm2d(512),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True),\n",
        "\t\t\t# [#, 14, 14, 512] => [#, 14, 14, 1024]\n",
        "\t\t\tnn.Conv2d(512, 1024, kernel_size=3, padding=1),\n",
        "\t\t\tnn.BatchNorm2d(1024),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True)\n",
        "\t\t)\n",
        "\t\tself.net = nn.Sequential(conv1, pool1, conv2, pool2, conv3, pool3, conv4, pool4, conv5)\n",
        "\t\n",
        "\tdef forward(self, X):\n",
        "\t\treturn self.net(X)\n",
        "\n",
        "\n",
        "class Yolo(nn.Module):\n",
        "\tdef __init__(self, backbone: YoloBackbone, backbone_out_channels=1024):\n",
        "\t\tsuper(Yolo, self).__init__()\n",
        "\t\tself.backbone = backbone\n",
        "\t\tself.head = nn.Sequential(\n",
        "\t\t\t# [#, 14, 14, ?] => [#, 14, 14, 1024]\n",
        "\t\t\tnn.Conv2d(backbone_out_channels, 1024, kernel_size=3, padding=1),\n",
        "\t\t\tnn.BatchNorm2d(1024),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True),\n",
        "\t\t\t# [#, 14, 14, 1024] => [#, 7, 7, 1024]\n",
        "\t\t\tnn.Conv2d(1024, 1024, kernel_size=3, padding=1, stride=2),\n",
        "\t\t\tnn.BatchNorm2d(1024),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True),\n",
        "\t\t\t# [#, 7, 7, 1024] => [#, 7, 7, 1024]\n",
        "\t\t\tnn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n",
        "\t\t\tnn.BatchNorm2d(1024),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True),\n",
        "\t\t\t# [#, 7, 7, 1024] => [#, 7, 7, 1024]\n",
        "\t\t\tnn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n",
        "\t\t\tnn.BatchNorm2d(1024),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True),\n",
        "\t\t\t# [#, 7, 7, 1024] => [#, 7*7*1024]\n",
        "\t\t\tnn.Flatten(),\n",
        "\t\t\t# [#, 7*7*1024] => [#, 4096]\n",
        "\t\t\tnn.Linear(7*7*1024, 4096),\n",
        "\t\t\t# nn.Dropout(0.5),\n",
        "\t\t\tnn.LeakyReLU(0.1, inplace=True),\n",
        "\t\t\t# [#, 4096] => [#, 7*7*30]\n",
        "\t\t\tnn.Linear(4096, 7*7*30),\n",
        "\t\t\tnn.Sigmoid(), #  normalize to [0, 1]\n",
        "\t\t\t# [#, 7*7*30] => [#, 7, 7, 30]\n",
        "\t\t\tnn.Unflatten(1, (7, 7, 30))\n",
        "\t\t)\n",
        "\t\tself.net = nn.Sequential(self.backbone, self.head)\n",
        "\n",
        "\tdef forward(self, X):\n",
        "\t\treturn self.net(X)\n",
        "\n",
        "\n",
        "class YoloPretrain(nn.Module):\n",
        "\tdef __init__(self, backbone: YoloBackbone):\n",
        "\t\tsuper(YoloPretrain, self).__init__()\n",
        "\t\tself.backbone = backbone\n",
        "\t\tself.head = nn.Sequential(\n",
        "\t\t\t# We use 224*224*3 to pretrain on ImageNet\n",
        "\t\t\t# so the output is [#, 7, 7, 1024]\n",
        "\t\t\tbackbone,\n",
        "\t\t\t# [#, 7, 7, 1024] => [#, 1, 1, 1024]\n",
        "\t\t\tnn.AdaptiveAvgPool2d((1, 1)),\n",
        "\t\t\t# [#, 1, 1, 1024] => [#, 1024]\n",
        "\t\t\tnn.Flatten(),\n",
        "\t\t\tnn.Linear(1024, 1000)\n",
        "\t\t)\n",
        "\t\tself.net = nn.Sequential(self.backbone, self.head)\n",
        "\n",
        "\tdef forward(self, X):\n",
        "\t\treturn self.net(X)\n",
        "\n",
        "\n",
        "def yolo_loss(yhat, y):\n",
        "\t\"\"\"\n",
        "\tArgs:\n",
        "\t\tyhat: [#, 7, 7, 30]\n",
        "\t\ty: [#, 7, 7, 30]\n",
        "\tReturns:\n",
        "\t\tloss: [#]\n",
        "\t\"\"\"\n",
        "\twith torch.no_grad():\n",
        "\t\t# arrange cell xidx, yidx\n",
        "\t\t# [7, 7]\n",
        "\t\tcell_xidx = (torch.arange(49) % 7).reshape(7, 7)\n",
        "\t\tcell_yidx = (torch.div(torch.arange(49), 7, rounding_mode='floor')).reshape(7, 7)\n",
        "\t\t# transform to [7, 7, 2]\n",
        "\t\tcell_xidx.unsqueeze_(-1)\n",
        "\t\tcell_yidx.unsqueeze_(-1)\n",
        "\t\tcell_xidx.expand(7, 7, 2)\n",
        "\t\tcell_yidx.expand(7, 7, 2)\n",
        "\t\t# move to device\n",
        "\t\tcell_xidx = cell_xidx.to(yhat.device)\n",
        "\t\tcell_yidx = cell_yidx.to(yhat.device)\n",
        "\n",
        "\tdef calc_coord(val):\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\t# transform cell relative coordinates to image relative coordinates\n",
        "\t\t\tx = (val[..., 0] + cell_xidx) / 7.0\n",
        "\t\t\ty = (val[..., 1] + cell_yidx) / 7.0\n",
        "\n",
        "\t\t\treturn (x - val[..., 2] / 2.0,\n",
        "\t\t\t\tx + val[..., 2] / 2.0,\n",
        "\t\t\t\ty - val[..., 3] / 2.0,\n",
        "\t\t\t\ty + val[..., 3] / 2.0)\n",
        "\n",
        "\ty_area = y[..., :10].reshape(-1, 7, 7, 2, 5)\n",
        "\tyhat_area = yhat[..., :10].reshape(-1, 7, 7, 2, 5)\n",
        "\n",
        "\ty_class = y[..., 10:].reshape(-1, 7, 7, 20)\n",
        "\tyhat_class = yhat[..., 10:].reshape(-1, 7, 7, 20)\n",
        "\n",
        "\twith torch.no_grad():\n",
        "\t\t# calculate IoU\n",
        "\t\tx_min, x_max, y_min, y_max = calc_coord(y_area)\n",
        "\t\tx_min_hat, x_max_hat, y_min_hat, y_max_hat = calc_coord(yhat_area)\n",
        "\n",
        "\t\twi = torch.min(x_max, x_max_hat) - torch.max(x_min, x_min_hat)\n",
        "\t\twi = torch.max(wi, torch.zeros_like(wi))\n",
        "\t\thi = torch.min(y_max, y_max_hat) - torch.max(y_min, y_min_hat)\n",
        "\t\thi = torch.max(hi, torch.zeros_like(hi))\n",
        "\n",
        "\t\tintersection = wi * hi\n",
        "\t\tunion = (x_max - x_min) * (y_max - y_min) + (x_max_hat - x_min_hat) * (y_max_hat - y_min_hat) - intersection\n",
        "\t\tiou = intersection / (union + 1e-6) # add epsilon to avoid nan\n",
        "\t\t\n",
        "\t\t_, res = iou.max(dim=3, keepdim=True)\n",
        "\t\n",
        "\t# [#, 7, 7, 5]\n",
        "\t# responsible bounding box (having higher IoU)\n",
        "\tyhat_res = torch.take_along_dim(yhat_area, res.unsqueeze(3), 3).squeeze_(3)\n",
        "\ty_res = y_area[..., 0, :5]\n",
        "\n",
        "\twith torch.no_grad():\n",
        "\t\t# calculate indicator matrix\n",
        "\t\thave_obj = y_res[..., 4] > 0\n",
        "\t\tno_obj = ~have_obj\n",
        "\t\n",
        "\treturn ((lambda_coord * ( # coordinate loss\n",
        "\t\t  (y_res[..., 0] - yhat_res[..., 0]) ** 2 # X\n",
        "\t\t+ (y_res[..., 1] - yhat_res[..., 1]) ** 2 # Y\n",
        "\t\t+ (torch.sqrt(y_res[..., 2]) - torch.sqrt(yhat_res[..., 2])) ** 2  # W\n",
        "\t\t+ (torch.sqrt(y_res[..., 3]) - torch.sqrt(yhat_res[..., 3])) ** 2) # H\n",
        "\t\t# confidence\n",
        "\t\t+ (y_res[..., 4] - yhat_res[..., 4]) ** 2\n",
        "\t\t# class\n",
        "\t\t+ ((y_class - yhat_class) ** 2).sum(dim=3)) * have_obj\n",
        "\t\t# noobj\n",
        "\t\t+ ((y_area[..., 0, 4] - yhat_area[..., 0, 4]) ** 2 + \\\n",
        "\t\t(y_area[..., 1, 4] - yhat_area[..., 1, 4]) ** 2) * no_obj * lambda_noobj).sum(dim=(1, 2))\n",
        "\n",
        "\n",
        "def pretrain(net, train_iter, test_iter, num_epochs, lr, momentum, weight_decay, device):\n",
        "\t# init params\n",
        "\tnet.apply(weight_init)\n",
        "\t# copy to device\n",
        "\tnet.to(device)\n",
        "\t# define optimizer\n",
        "\toptimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "\tloss = nn.CrossEntropyLoss()\n",
        "\t# train\n",
        "\t# TODO: IMPLEMENT HERE\n",
        "\n",
        "\n",
        "def train(net, train_iter, test_iter, num_epochs, lr, momentum, weight_decay, num_gpu=1, accum_batch_num=1, save_path='./model', load=None, load_epoch=-1, pretrained=False):\n",
        "\t'''\n",
        "\tTrain net work. Some notes for load & load_epoch:\n",
        "\t:param load: the file of model weights to load\n",
        "\t:param load_epoch: num of epoch already completed (minus 1). should be the same with the number in auto-saved file name.\n",
        "\t'''\n",
        "\t\n",
        "\tdef print_and_log(msg, log_file):\n",
        "\t\tprint(msg)\n",
        "\t\twith open(log_file, 'a', encoding='utf8') as f:\n",
        "\t\t\tf.write(msg + '\\n')\n",
        "\n",
        "\tdef update_lr(opt, lr):\n",
        "\t\tfor param_group in opt.param_groups:\n",
        "\t\t\tparam_group['lr'] = lr\n",
        "\n",
        "\tdef get_all_gpu(num_gpu):\n",
        "\t\treturn [torch.device('cuda:' + str(i)) for i in range(num_gpu)]\n",
        "\n",
        "\tos.makedirs(save_path, exist_ok=True)\n",
        "\tlog_file = os.path.join(save_path, f'log-{time.time_ns()}.txt')\n",
        "\n",
        "\tif load:\n",
        "\t\tnet.load_state_dict(torch.load(load))\n",
        "\telif pretrained:\n",
        "\t\tnet.head.apply(weight_init)\n",
        "\telse:\n",
        "\t\t# init params\n",
        "\t\tnet.apply(weight_init)\n",
        "\t\n",
        "\t# copy to device\n",
        "\tif not torch.cuda.is_available():\n",
        "\t\tnet = net.to(torch.device('cpu'))\n",
        "\t\tdevices = [torch.device('cpu')]\n",
        "\telse:\n",
        "\t\tif num_gpu > 1:\n",
        "\t\t\tnet = nn.DataParallel(net, get_all_gpu(num_gpu))\n",
        "\t\t\tdevices = get_all_gpu(num_gpu)\n",
        "\t\telse:\n",
        "\t\t\tnet = net.to(torch.device('cuda'))\n",
        "\t\t\tdevices = [torch.device('cuda')]\n",
        "\t# define optimizer\n",
        "\tif isinstance(lr, float):\n",
        "\t\ttlr = lr\n",
        "\telse: tlr = 0.001\n",
        "\t\n",
        "\toptimizer = torch.optim.SGD(net.parameters(), lr=tlr, momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "\t# visualization\n",
        "\tanimator = Animator(xlabel='epoch', xlim=[0, num_epochs], legend=['train loss', 'test loss'])\n",
        "\n",
        "\tnum_batches = len(train_iter)\n",
        "\t# train\n",
        "\tfor epoch in range(num_epochs - load_epoch - 1):\n",
        "\t\t# adjust true epoch number according to pre_load\n",
        "\t\tepoch = epoch + load_epoch + 1\n",
        "\t\t\n",
        "\t\t# define metrics: train loss, sample count\n",
        "\t\tmetrics = Accumulator(2)\n",
        "\t\t# define timer\n",
        "\t\ttimer = Timer()\n",
        "\t\t\n",
        "\t\t# train\n",
        "\t\tnet.train()\n",
        "\n",
        "\t\t# set batch accumulator\n",
        "\t\taccum_cnt = 0\n",
        "\t\taccum = 0\n",
        "\t\t\n",
        "\t\tfor i, batch in enumerate(train_iter):\n",
        "\t\t\ttimer.start()\n",
        "\n",
        "\t\t\tX, y = batch\n",
        "\t\t\tX, y = X.to(devices[0]), y.to(devices[0])\n",
        "\t\t\tyhat = net(X)\n",
        "\n",
        "\t\t\tloss_val = yolo_loss(yhat, y)\n",
        "\n",
        "\t\t\t# backward to accumulate gradients\n",
        "\t\t\tloss_val.sum().backward()\n",
        "\t\t\t# update batch accumulator\n",
        "\t\t\taccum += 1\n",
        "\t\t\taccum_cnt += loss_val.shape[0]\n",
        "\t\t\t# step when accumulator is full\n",
        "\t\t\tif accum == accum_batch_num or i == num_batches - 1:\n",
        "\t\t\t\t# update learning rate per epoch and adjust by accumulated batch_size\n",
        "\t\t\t\tif callable(lr):\n",
        "\t\t\t\t\tupdate_lr(optimizer, lr(epoch) / accum_cnt)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tupdate_lr(optimizer, lr / accum_cnt)\n",
        "\t\t\t\t# step\n",
        "\t\t\t\toptimizer.step()\n",
        "\t\t\t\t# clear\n",
        "\t\t\t\toptimizer.zero_grad()\n",
        "\t\t\t\taccum_cnt = 0\n",
        "\t\t\t\taccum = 0\n",
        "\n",
        "\t\t\t# update metrics\n",
        "\t\t\twith torch.no_grad():\n",
        "\t\t\t\tmetrics.add(loss_val.sum().cpu(), X.shape[0])\n",
        "\t\t\ttrain_l = metrics[0] / metrics[1]\n",
        "\t\t\t\n",
        "\t\t\ttimer.stop()\n",
        "\t\t\t\n",
        "\t\t\t# log & visualization\n",
        "\t\t\tif (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
        "\t\t\t\tprint_and_log(\"epoch: %d, batch: %d / %d, loss: %.4f, time: %.4f\" % (epoch, i + 1, num_batches, train_l.item(), timer.sum()), log_file)\n",
        "\t\t\t\tanimator.add(epoch + (i + 1) / num_batches, (train_l, None))\n",
        "\t\t\n",
        "\t\t# redefine metrics: test loss, test sample count\n",
        "\t\tmetrics = Accumulator(2)\n",
        "\t\t# redefine timer\n",
        "\t\ttimer = Timer()\n",
        "\t\t# test\n",
        "\t\tnet.eval()\n",
        "\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\ttimer.start()\n",
        "\t\t\t\n",
        "\t\t\tfor batch in test_iter:\n",
        "\t\t\t\tX, y = batch\n",
        "\t\t\t\tX, y = X.to(devices[0]), y.to(devices[0])\n",
        "\t\t\t\tyhat = net(X)\n",
        "\n",
        "\t\t\t\tloss_val = yolo_loss(yhat, y)\n",
        "\t\t\t\tmetrics.add(loss_val.sum().cpu(), X.shape[0])\n",
        "\t\t\t\n",
        "\t\t\ttimer.stop()\n",
        "\t\t\t\n",
        "\t\t\ttest_l = metrics[0] / metrics[1]\n",
        "\t\t\tprint_and_log(\"epoch: %d, test loss: %.4f, time: %.4f\" % (epoch + 1, test_l.item(), timer.sum()), log_file)\n",
        "\t\t\tanimator.add(epoch + 1, (None, test_l))\n",
        "\n",
        "\t\t# save model\n",
        "\t\ttorch.save(net.state_dict(), os.path.join(save_path, f'./{time.time_ns()}-epoch-{epoch}.pth'))\n",
        "\n",
        "\n",
        "def nms(pred, threshold=0.5):\n",
        "\t'''\n",
        "\tNon-maximum suppression directly for output.\n",
        "\t:param pred: pred results\n",
        "\t:param threshold:\n",
        "\t:return:\n",
        "\t'''\n",
        "\twith torch.no_grad():\n",
        "\t\tpred = pred.reshape((-1, 30))\n",
        "\t\t# [[idx, x, y, w, h, iou, score_cls]]\n",
        "\t\tnms_data = [[] for _ in range(20)]\n",
        "\t\tfor i in range(pred.shape[0]):\n",
        "\t\t\tcell = pred[i]\n",
        "\t\t\tscore, idx = torch.max(cell[10:30], dim=0)\n",
        "\t\t\tidx = idx.item()\n",
        "\t\t\tx, y, w, h, iou = cell[0:5].cpu().numpy()\n",
        "\n",
        "\t\t\tnms_data[idx].append([i, x, y, w, h, iou, score.item()])\n",
        "\t\t\tx, y, w, h, iou = cell[5:10].cpu().numpy()\n",
        "\t\t\tnms_data[idx].append([i, x, y, w, h, iou, score.item()])\n",
        "\n",
        "\t\tret = torch.zeros_like(pred)\n",
        "\t\tflag = torch.zeros(pred.shape[0], dtype=torch.bool)\n",
        "\t\tfor c in range(20):\n",
        "\t\t\tc_nms_data = np.array(nms_data[c])\n",
        "\n",
        "\t\t\tkeep_index = _nms(c_nms_data, threshold)\n",
        "\t\t\tkeeps = c_nms_data[keep_index]\n",
        "\n",
        "\t\t\tfor keep in keeps:\n",
        "\t\t\t\ti, x, y, w, h, iou, score = keep\n",
        "\t\t\t\ti = int(i)\n",
        "\t\t\t\t\n",
        "\t\t\t\tlast_score, _ = torch.max(ret[i][10:30], dim=0)\n",
        "\t\t\t\tlast_iou = ret[i][4]\n",
        "\n",
        "\t\t\t\tif score * iou > last_score * last_iou:\n",
        "\t\t\t\t\tflag[i] = False\n",
        "\t\t\t\tif flag[i]: continue\n",
        "\t\t\t\t\n",
        "\t\t\t\tret[i][0:5] = torch.tensor([x, y, w, h, iou])\n",
        "\t\t\t\tret[i][10:30] = 0\n",
        "\t\t\t\tret[i][10 + c] = score\n",
        "\n",
        "\t\t\t\tflag[i] = True\n",
        "\n",
        "\t\treturn ret\n",
        "\n",
        "\n",
        "def _nms(data, threshold):\n",
        "\t'''\n",
        "\tNon-maximum suppression.\n",
        "\t:param data: numpy data array (i, x, y, w, h, score_area, score_cls)\n",
        "\t:param threshold:\n",
        "\t:return: keep index array\n",
        "\t'''\n",
        "\tif len(data) == 0:\n",
        "\t\treturn []\n",
        "\n",
        "\t# cell relative coordinates\n",
        "\tcell_idx = data[:, 0]\n",
        "\tx = data[:, 1]\n",
        "\ty = data[:, 2]\n",
        "\t# calculate cell index\n",
        "\txidx = cell_idx % 7\n",
        "\tyidx = cell_idx // 7\n",
        "\t# transform to image relative coordinates\n",
        "\tx = (x + xidx) / 7.0\n",
        "\ty = (y + yidx) / 7.0\n",
        "\t# obtain image relative width & height\n",
        "\tw = data[:, 3]\n",
        "\th = data[:, 4]\n",
        "\t# calculate coordinates\n",
        "\tx1 = x - w / 2\n",
        "\ty1 = y - h / 2\n",
        "\tx2 = x + w / 2\n",
        "\ty2 = y + h / 2\n",
        "\n",
        "\tscore_area = data[:, 5]\n",
        "\n",
        "\tareas = w * h\n",
        "\t\n",
        "\torder = score_area.argsort()[::-1]\n",
        "\tkeep = []\n",
        "\n",
        "\twhile order.size > 0:\n",
        "\t\ti = order[0]\n",
        "\t\tkeep.append(i)\n",
        "\t\txx1 = np.maximum(x1[i], x1[order[1:]])\n",
        "\t\tyy1 = np.maximum(y1[i], y1[order[1:]])\n",
        "\t\txx2 = np.minimum(x2[i], x2[order[1:]])\n",
        "\t\tyy2 = np.minimum(y2[i], y2[order[1:]])\n",
        "\n",
        "\t\tw = np.maximum(0.0, xx2 - xx1)\n",
        "\t\th = np.maximum(0.0, yy2 - yy1)\n",
        "\t\tinter = w * h\n",
        "\t\tovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
        "\n",
        "\t\tinds = np.where(ovr <= threshold)[0]\n",
        "\t\torder = order[inds + 1]\n",
        "\t\n",
        "\treturn keep\n"
      ],
      "metadata": {
        "id": "mIuhBYq8gX9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KHdiV5WUPe_"
      },
      "outputs": [],
      "source": [
        "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
        "backbone = nn.Sequential(*list(resnet18.children())[:-2]) # remove avg pool and fc\n",
        "net = Yolo(backbone, backbone_out_channels=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "kTV5UDYuUPe_",
        "outputId": "104604cd-4c3c-4b9b-a128-91f3f0550e1f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4e7cb66cd24c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m145\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m145\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccum_batch_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-c91f9d8cd56d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, test_iter, num_epochs, lr, momentum, weight_decay, num_gpu, accum_batch_num, save_path, load, load_epoch, pretrained)\u001b[0m\n\u001b[1;32m    357\u001b[0m                         \u001b[0;31m# update metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                                 \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                         \u001b[0mtrain_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 252x180 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def lr(epoch):\n",
        "    if epoch < 10: return 0.001 * (epoch + 1)\n",
        "    if epoch < 85: return 0.01\n",
        "    if epoch < 115: return 0.001\n",
        "    if epoch < 145: return 0.0001\n",
        "\n",
        "train(net, train_iter, test_iter, 145, lr=lr, momentum=0.9, weight_decay=5e-4, accum_batch_num=4, save_path='./model', pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_weight_path = './model/resnet18-pretrained-epoch-145.pth'\n",
        "\n",
        "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
        "backbone = nn.Sequential(*list(resnet18.children())[:-2]) # remove avg pool and fc\n",
        "net = yolo.Yolo(backbone, backbone_out_channels=512)\n",
        "\n",
        "net.load_state_dict(torch.load(model_weight_path))"
      ],
      "metadata": {
        "id": "za2Qs8VKhZ8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_one_batch(net, test_iter_raw, 'cuda')"
      ],
      "metadata": {
        "id": "EGSOlmjQqGVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_fps(net, test_iter_raw, 'cuda')"
      ],
      "metadata": {
        "id": "58AbnK7DqLm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_and_draw_mAP(net, test_iter_raw, 'cuda')"
      ],
      "metadata": {
        "id": "kkxgp1N3qMfK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "ab187dc4f90bff2e4e5b6910e1a0b0407affa61bc1c8fc0d08997240349c52fc"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7fa97b5ae8454361a5f2c9f2ec3060dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94764f5b7ea241b5bf6d10ad42f8b0e5",
              "IPY_MODEL_beb9084e8f394f9bb8147f76af1cc929",
              "IPY_MODEL_63e579fc4b8548feaed3b441fd1cf2a6"
            ],
            "layout": "IPY_MODEL_e00657afc0ba4ba3a78fa7ad329d9018"
          }
        },
        "94764f5b7ea241b5bf6d10ad42f8b0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ee224f9f9b84f65bdb89b4db645bb6d",
            "placeholder": "​",
            "style": "IPY_MODEL_68859a2729064fddaf603b85028f3954",
            "value": "100%"
          }
        },
        "beb9084e8f394f9bb8147f76af1cc929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd1db780edfd4e26942d5e56af4cd16a",
            "max": 460032000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e444f4064b2c44a19ccefd6bf1eb87d4",
            "value": 460032000
          }
        },
        "63e579fc4b8548feaed3b441fd1cf2a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdd94c09c4864ea48a84b8e9b8e84ec5",
            "placeholder": "​",
            "style": "IPY_MODEL_48247bf0644647dab8aad2ec5e07bca4",
            "value": " 460032000/460032000 [00:35&lt;00:00, 13359620.14it/s]"
          }
        },
        "e00657afc0ba4ba3a78fa7ad329d9018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee224f9f9b84f65bdb89b4db645bb6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68859a2729064fddaf603b85028f3954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd1db780edfd4e26942d5e56af4cd16a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e444f4064b2c44a19ccefd6bf1eb87d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdd94c09c4864ea48a84b8e9b8e84ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48247bf0644647dab8aad2ec5e07bca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13f70f911e234fbabb88163c48a0d8ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0780a1586db74b24bf0a538e5bf7f7dd",
              "IPY_MODEL_c20ad8749f3040b4afee3ef9bbd02731",
              "IPY_MODEL_495c067312564939be4047d682f68f75"
            ],
            "layout": "IPY_MODEL_6a60adfd7a1343c5b1e414f3c52d2d2d"
          }
        },
        "0780a1586db74b24bf0a538e5bf7f7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_772717d673bd429c878aa81f1ef86295",
            "placeholder": "​",
            "style": "IPY_MODEL_d120bc4bcc2047c8ab03b222875dc3ef",
            "value": "100%"
          }
        },
        "c20ad8749f3040b4afee3ef9bbd02731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7143f2b364145648157c3210a7485f0",
            "max": 451020800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7be6a8d22ba948cba48b87e9cded5eac",
            "value": 451020800
          }
        },
        "495c067312564939be4047d682f68f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42b17391227b457aae0158dbb30996d3",
            "placeholder": "​",
            "style": "IPY_MODEL_1c454ed3c7664257a3b435301afc237d",
            "value": " 451020800/451020800 [00:38&lt;00:00, 11399038.03it/s]"
          }
        },
        "6a60adfd7a1343c5b1e414f3c52d2d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "772717d673bd429c878aa81f1ef86295": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d120bc4bcc2047c8ab03b222875dc3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7143f2b364145648157c3210a7485f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7be6a8d22ba948cba48b87e9cded5eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42b17391227b457aae0158dbb30996d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c454ed3c7664257a3b435301afc237d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1158e7fb99e436aa7beaa70d85c5b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4e154849346411b8e98926fdaf49952",
              "IPY_MODEL_66aae6d7af344e23bf1de595a96dee11",
              "IPY_MODEL_79877b0fefa344629f64f28d6791a34e"
            ],
            "layout": "IPY_MODEL_e412216e7c2743b9bcf75f0d88016898"
          }
        },
        "f4e154849346411b8e98926fdaf49952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d63469d63d9944188045218f1da4b46e",
            "placeholder": "​",
            "style": "IPY_MODEL_dbf6853fc87845c981f01b294cbc65e9",
            "value": "100%"
          }
        },
        "66aae6d7af344e23bf1de595a96dee11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e15d51ed815947eca43d3b53cd922638",
            "max": 1999639040,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70dd342df73344c699d1495d85c8d27a",
            "value": 1999639040
          }
        },
        "79877b0fefa344629f64f28d6791a34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_971fd61c1ff84a71893fa89bea2a269e",
            "placeholder": "​",
            "style": "IPY_MODEL_d92092b0fef74fe7b015b2789c8f6a8d",
            "value": " 1999639040/1999639040 [02:24&lt;00:00, 14283981.12it/s]"
          }
        },
        "e412216e7c2743b9bcf75f0d88016898": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d63469d63d9944188045218f1da4b46e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbf6853fc87845c981f01b294cbc65e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e15d51ed815947eca43d3b53cd922638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70dd342df73344c699d1495d85c8d27a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "971fd61c1ff84a71893fa89bea2a269e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d92092b0fef74fe7b015b2789c8f6a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}